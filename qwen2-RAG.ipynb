{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35699f19-4c98-418a-b4d4-4e9cb755d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install  \"unstructured[all-docs]\" chromadb langchain ollama langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86353544-91b3-4bae-b2ff-d275df1d4860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest в ™ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest в № \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest в ё \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest в ј \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest в ј \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest в ¦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest в ¦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest в ‡ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest в Џ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 43f7a214e532... 100% в–•в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–Џ 4.4 GB                         \n",
      "pulling 62fbfd9ed093... 100% в–•в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–Џ  182 B                         \n",
      "pulling c156170b718e... 100% в–•в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–Џ  11 KB                         \n",
      "pulling f02dd72bb242... 100% в–•в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–Џ   59 B                         \n",
      "pulling 648f809ced2b... 100% в–•в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–Џ  485 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "removing any unused layers \n",
      "success \u001b[?25h\n",
      "\u001b[?25lpulling manifest в ™ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest в № \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest в ё \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest в ј \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest в ґ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest в ¦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest в § \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest в ‡ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest в Џ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 970aa74c0a90... 100% в–•в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–Џ 274 MB                         \n",
      "pulling c71d239df917... 100% в–•в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–Џ  11 KB                         \n",
      "pulling ce4a164fc046... 100% в–•в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–Џ   17 B                         \n",
      "pulling 31df23ea7daa... 100% в–•в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–€в–Џ  420 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "removing any unused layers \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull qwen2:7b \n",
    "!ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ba03ba0-dc4f-40e4-8299-b22b34765bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                    \tID          \tSIZE  \tMODIFIED               \n",
      "nomic-embed-text:latest \t0a109f422b47\t274 MB\tLess than a second ago\t\n",
      "qwen2:7b                \te0d4e1163c58\t4.4 GB\t1 second ago          \t\n",
      "llama3:latest           \t365c0bd3c000\t4.7 GB\t44 hours ago          \t\n",
      "qwen2:7b-instruct-q3_K_M\tf27ce4958e87\t3.8 GB\t45 hours ago          \t\n",
      "qwen2:1.5b              \tf6daf2b25194\t934 MB\t45 hours ago          \t\n",
      "llama2-uncensored:latest\t44040b922233\t3.8 GB\t5 days ago            \t\n",
      "moondream:latest        \t55fc3abd3867\t1.7 GB\t7 days ago            \t\n",
      "phi3:latest             \t64c1188f2485\t2.4 GB\t9 days ago            \t\n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53473de4-fcd8-45e3-88a3-bb2aa07adf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "dir_path='./data'\n",
    "\n",
    "def load_documents(data_path):\n",
    "    loader= DirectoryLoader(data_path, glob='*')\n",
    "    return loader.load()\n",
    "\n",
    "documents=load_documents(dir_path)\n",
    "# print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5986fdf-cf34-4524-86e5-b20561e96786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_text(documents:list):\n",
    "    text_spliter= RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1500,\n",
    "        chunk_overlap=300,\n",
    "        length_function=len,\n",
    "        add_start_index=True\n",
    "    )\n",
    "\n",
    "    chunks=text_spliter.split_documents(documents)\n",
    "    return chunks\n",
    "\n",
    "chunks=split_text(documents)\n",
    "# print(chunks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f78dba-bb47-4959-af5f-79b82634c18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 21/21 [00:52<00:00,  2.51s/it]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "ollama_emb = OllamaEmbeddings(model=\"nomic-embed-text\",show_progress=True)\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=ollama_emb,persist_directory=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ef5b96e-1996-4283-aede-e1ee887d15e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler \n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "    Use three sentences maximum and keep the answer as concise as possible.\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    Helpful Answer:\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=template,\n",
    "    )\n",
    "\n",
    "llm = Ollama(model=\"qwen2:7b\", callback_manager = CallbackManager([StreamingStdOutCallbackHandler()]))\n",
    "\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f00307e9-8ffe-4ba7-ac82-d0d50e728c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Your question(/bye for exit):  What is the thirty-first rule of the Internet?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\plumb\\anaconda3\\envs\\ollama_agent\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The thirty-first rule of the Internet is: \"Tits or GTFO—the choice is yours.\""
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Your question(/bye for exit):   What is the third rule of the Internet?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:04<00:00,  4.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The third rule of the Internet is \"We are Anonymous.\""
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Your question(/bye for exit):  What is the number of the rule that says that the internet makes you stupid?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:04<00:00,  4.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 77 states that \"The Internet makes you stupid.\""
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Your question(/bye for exit):  What is the conclusion?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:04<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The conclusion from the provided data seems to highlight that there are significant differences in language usage among bloggers based on their ages (10s, 20s, 30s) and genders. The analysis shows variations in the frequency of word classes and specific words used by different age groups and both male and female authors. The researchers have found statistically significant differences in these linguistic patterns.\n",
      "\n",
      "The true test of significance is then presented as whether these observed differences can be effectively utilized to predict an author's age and gender. This suggests that if there are indeed meaningful variations between the language profiles of bloggers across the specified demographics, it would be possible to develop models or systems that could automatically profile authors based on their written content.\n",
      "\n",
      "Thus, the conclusion might emphasize the potential for developing automated tools capable of identifying blogging styles related to age and gender through analyzing linguistic characteristics. The effectiveness of these tools would rely on the robustness and discriminative power of the differences observed in language use among bloggers of different ages and genders."
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Your question(/bye for exit):  /bye\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    YOUR_QUESTION = input(\"\\nYour question(/bye for exit): \")\n",
    "    if YOUR_QUESTION == \"/bye\":\n",
    "        break\n",
    "    if YOUR_QUESTION.strip() == \"\":\n",
    "        continue\n",
    "\n",
    "    result = qa_chain({\"query\": YOUR_QUESTION })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b986831-3211-4803-ba50-669c2cd41e31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
